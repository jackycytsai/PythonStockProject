{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapitalData(date_str):\n",
    "\n",
    "    #datestr = '20231002'\n",
    "    datestr = date_str\n",
    "\n",
    "    r = requests.get('https://www.twse.com.tw/rwd/zh/fund/T86?date=' + datestr + '&selectType=ALLBUT0999&response=csv')\n",
    "\n",
    "    # 整理資料，變成表格\n",
    "\n",
    "    df = pd.read_csv(StringIO(r.text.replace(\"=\", \"\")), header=1).dropna(how='all', axis=1).dropna(how='any')\n",
    "\n",
    "    # Remove Column\n",
    "    df = df.drop(columns='外資自營商買進股數')\n",
    "    df = df.drop(columns='外資自營商賣出股數')\n",
    "    df = df.drop(columns='外資自營商買賣超股數')\n",
    "\n",
    "    field_names = [\n",
    "    'code',\n",
    "    'name',\n",
    "    'ForeignInvestorBuyShares',\n",
    "    'ForeignInvestorSellShares',\n",
    "    'ForeignInvestorNetShares',\n",
    "    'InvestmentTrustBuyShares',\n",
    "    'InvestmentTrustSellShares',\n",
    "    'InvestmentTrustNetShares',\n",
    "    'DealerSelfNetTotalShares',\n",
    "    'DealerSelfBuyShares',\n",
    "    'DealerSelfSellShares',\n",
    "    'DealerSelfNetShares',\n",
    "    'DealerSelfBuySharesHedge',\n",
    "    'DealerSelfSellSharesHedge',\n",
    "    'DealerSelfNetSharesHedge',\n",
    "    'TotalCapitalQuantity'\n",
    "    ]\n",
    "\n",
    "    # Rename the columns of the DataFrame\n",
    "    df.columns = field_names\n",
    "\n",
    "    # Turn into numeric\n",
    "    df[df.columns[2:]] = df[df.columns[2:]].applymap(lambda x: pd.to_numeric(str(x).replace(\",\", \"\"), errors='coerce'))\n",
    "\n",
    "    # Insert Date\n",
    "    df['Date'] = datestr\n",
    "\n",
    "    # Convert the 'Date' column to datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start date and end date\n",
    "start_date = datetime.date(2023, 9, 25)\n",
    "end_date = datetime.date(2023, 10, 3)\n",
    "\n",
    "# Generate a date range between start_date and end_date\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Filter the date range to keep only weekdays (Monday to Friday)\n",
    "workdays = [date for date in date_range if date.weekday() < 5]\n",
    "\n",
    "# Convert the workdays to a list of strings in the format 'YYYY-MM-DD'\n",
    "workdays_str = [date.strftime('%Y%m%d') for date in workdays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Initialize the tqdm progress bar\n",
    "for date_str in tqdm(workdays_str):\n",
    "    try:\n",
    "        data = CapitalData(date_str)\n",
    "        \n",
    "        # Concatenate the data to the all_data DataFrame\n",
    "        all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "print(\"Finish Collecting!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Replace this with your service account key file path\n",
    "service_account_key_path = \"StockBiqQueryKey.json\"\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client.from_service_account_json(service_account_key_path)\n",
    "\n",
    "# Define the schema for your table\n",
    "schema = [\n",
    "    bigquery.SchemaField('code', 'STRING'),\n",
    "    bigquery.SchemaField('name', 'STRING'),\n",
    "    bigquery.SchemaField('ForeignInvestorBuyShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('ForeignInvestorSellShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('ForeignInvestorNetShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('InvestmentTrustBuyShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('InvestmentTrustSellShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('InvestmentTrustNetShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('DealerSelfNetTotalShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('DealerSelfBuyShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('DealerSelfSellShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('DealerSelfNetShares', 'INTEGER'),\n",
    "    bigquery.SchemaField('DealerSelfBuyShareshedge', 'INTEGER'),\n",
    "    bigquery.SchemaField('DealerSelfSellShareshedge', 'INTEGER'),\n",
    "    bigquery.SchemaField('DealerSelfNetShareshedge', 'INTEGER'),\n",
    "    bigquery.SchemaField('TotalCapitalQuantity', 'INTEGER'),\n",
    "    bigquery.SchemaField('date', 'DATE')\n",
    "]\n",
    "\n",
    "# Define the dataset and table ID\n",
    "dataset_id = 'PythonStock'  # Replace with your dataset ID\n",
    "table_id = 'DailyStock_Capital'      # Replace with your table ID\n",
    "\n",
    "# Create a dataset reference\n",
    "dataset_ref = client.dataset(dataset_id)\n",
    "\n",
    "# Create the table with the specified schema\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "table = client.create_table(table)  # Create the table\n",
    "\n",
    "print(f\"Table {table_id} created in dataset {dataset_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert into BigQuery\n",
    "job = client.load_table_from_dataframe(data, table_ref)\n",
    "job.result()  #等待寫入完成\n",
    "\n",
    "print(\"Mission Complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For google cloud function\n",
    "from google.cloud import bigquery\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import io\n",
    "from io import StringIO\n",
    "\n",
    "def CapitalTable(request):\n",
    "\n",
    "    # Line notify\n",
    "    def lineNotifyMessage(msg):\n",
    "\n",
    "            headers = {\n",
    "            \"Authorization\": \"Bearer \" + 'jbScjQe6jY16zTILgQMN1REp6UHeJgCNAXFdJ82P8TZ', \n",
    "            \"Content-Type\" : \"application/x-www-form-urlencoded\"\n",
    "            }\n",
    "\n",
    "            payload = {'message': msg }\n",
    "            r = requests.post(\"https://notify-api.line.me/api/notify\", headers = headers, params = payload)\n",
    "\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    # Format the date as 'yyyymmdd'\n",
    "    datestr = today.strftime('%Y%m%d')\n",
    "\n",
    "    # Try if data exists\n",
    "    try:\n",
    "        r = requests.get('https://www.twse.com.tw/rwd/zh/fund/T86?date=' + datestr + '&selectType=ALLBUT0999&response=csv')\n",
    "\n",
    "        # 整理資料，變成表格\n",
    "        df = pd.read_csv(StringIO(r.text.replace(\"=\", \"\")), header=1).dropna(how='all', axis=1).dropna(how='any')\n",
    "\n",
    "        # Remove Column\n",
    "        df = df.drop(columns='外資自營商買進股數')\n",
    "        df = df.drop(columns='外資自營商賣出股數')\n",
    "        df = df.drop(columns='外資自營商買賣超股數')\n",
    "\n",
    "        field_names = [\n",
    "        'code',\n",
    "        'name',\n",
    "        'ForeignInvestorBuyShares',\n",
    "        'ForeignInvestorSellShares',\n",
    "        'ForeignInvestorNetShares',\n",
    "        'InvestmentTrustBuyShares',\n",
    "        'InvestmentTrustSellShares',\n",
    "        'InvestmentTrustNetShares',\n",
    "        'DealerSelfNetTotalShares',\n",
    "        'DealerSelfBuyShares',\n",
    "        'DealerSelfSellShares',\n",
    "        'DealerSelfNetShares',\n",
    "        'DealerSelfBuySharesHedge',\n",
    "        'DealerSelfSellSharesHedge',\n",
    "        'DealerSelfNetSharesHedge',\n",
    "        'TotalCapitalQuantity'\n",
    "        ]\n",
    "\n",
    "        # Rename the columns of the DataFrame\n",
    "        df.columns = field_names\n",
    "\n",
    "        # Turn into numeric\n",
    "        df[df.columns[2:]] = df[df.columns[2:]].map(lambda x: pd.to_numeric(str(x).replace(\",\", \"\"), errors='coerce'))\n",
    "\n",
    "        # Insert Date\n",
    "        df['Date'] = datestr\n",
    "\n",
    "        # Convert the 'Date' column to datetime format\n",
    "        df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "\n",
    "        ## Get BiqQuery Set up\n",
    "        client = bigquery.Client()\n",
    "        dataset_id = 'PythonStock'\n",
    "        table_id = 'DailyStock_Capital'\n",
    "        table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "        print(table_ref)\n",
    "        print(client)\n",
    "\n",
    "        job = client.load_table_from_dataframe(df, table_ref)\n",
    "        job.result()  # Wait for completing\n",
    "        \n",
    "        lineNotifyMessage(\"{} Capital Data Inserted\".format(datestr))\n",
    "        return \"{} Capital Data Inserted\".format(datestr)\n",
    "        \n",
    "    except:\n",
    "        lineNotifyMessage(\"{} Capital Data Inserted\".format(datestr))\n",
    "        return \"{} Capital Data is null\".format(datestr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Temporaly Using\n",
    "data = CapitalData('20231003')\n",
    "\n",
    "dataset_id = 'PythonStock'\n",
    "table_id = 'DailyStock_Capital'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "# Insert into BigQuery\n",
    "job = client.load_table_from_dataframe(data, table_ref)\n",
    "job.result()  # Wait for completing\n",
    "\n",
    "# Line notify\n",
    "def lineNotifyMessage(msg):\n",
    "\n",
    "        headers = {\n",
    "        \"Authorization\": \"Bearer \" + 'jbScjQe6jY16zTILgQMN1REp6UHeJgCNAXFdJ82P8TZ', \n",
    "        \"Content-Type\" : \"application/x-www-form-urlencoded\"\n",
    "        }\n",
    "\n",
    "        payload = {'message': msg }\n",
    "        r = requests.post(\"https://notify-api.line.me/api/notify\", headers = headers, params = payload)\n",
    "\n",
    "lineNotifyMessage(\"{} Capital Data Inserted\".format('20231003'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
